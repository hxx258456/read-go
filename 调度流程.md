# 程序的入口——rt0_xxxx_amd64.s

不同cpu架构下程序入口不同，以amd64为例：

- MacOS在src/runtime/rt0_drawin_amd64.s
- Linux在src/runtime/rt0_linux_amd64.s
- Windows在src/runtime/rt0_windows_amd64.s

> rt0 是runtime0的缩写，代表运行时的创建者

以Linux系统为例:

```assembly
TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8
	JMP	_rt0_amd64(SB) // 跳转至_rt0_amd64
```

```assembly
// _rt0_amd64 is common startup code for most amd64 systems when using
// internal linking. This is the entry point for the program from the
// kernel for an ordinary -buildmode=exe program. The stack holds the
// number of arguments and the C-style argv.
// 该代码的作用是将输入的`argc`和`argv`从内存移入到寄存器当中，执行完成之后，栈指针SP的前两个值分别为`argc`和`argv`，其对应参数的数量和具体参数值。
TEXT _rt0_amd64(SB),NOSPLIT,$-8
	MOVQ	0(SP), DI	// argc
	LEAQ	8(SP), SI	// argv
	JMP	runtime·rt0_go(SB) // 跳转至rt0_go
```

```assembly
TEXT runtime·rt0_go(SB),NOSPLIT|TOPFRAME,$0
	...
	
	// 程序刚启动的时候必定有一个线程启动（主线程）
	// 将当前的栈和资源保存在g0
	// 将该线程保存在m0
	// tls: Thread Local Storage
    // set the per-goroutine and per-mach "registers"
    get_tls(BX)
	LEAQ	runtime·g0(SB), CX
	MOVQ	CX, g(BX)
	LEAQ	runtime·m0(SB), AX

	// save m->g0 = g0
	MOVQ	CX, m_g0(AX)
	// save m0 to g0->m
	MOVQ	AX, g_m(CX)
	...
	
	CALL	runtime·check(SB) // 运行时类型检查，主要是校验编译器的翻译工作是否正确

	MOVL	24(SP), AX		// copy argc
	MOVL	AX, 0(SP)
	MOVQ	32(SP), AX		// copy argv
	MOVQ	AX, 8(SP)
	CALL	runtime·args(SB) // 系统参数传递，主要是将系统参数转换传递给程序使用。
	CALL	runtime·osinit(SB) // 系统基本参数设置，主要是获取 CPU 核心数和内存物理页大小
	CALL	runtime·schedinit(SB) // 调度器初始化

	// create a new goroutine to start program
	MOVQ	$runtime·mainPC(SB), AX		// 获取runtime.main函数
	PUSHQ	AX
	CALL	runtime·newproc(SB) // 以runtime.main函数创建一个协程
	POPQ	AX

	// start this M
	CALL	runtime·mstart(SB) // 启动m，调度器开始进行循环调度

	CALL	runtime·abort(SB)	// mstart should never return
	RET
	
DATA	runtime·mainPC+0(SB)/8,$runtime·main<ABIInternal>(SB) // 调用runtime.main函数

TEXT runtime·mstart(SB),NOSPLIT|TOPFRAME,$0
	CALL	runtime·mstart0(SB) // 可以看出mstart实际调用的是mstart0函数
	RET // not reached
```

以上就是汇编部分程序启动流程，下面深入看看osinit,schedinit,newproc,mstart0这些方法运行时工作流程

```go
// src/runtime/os_linux.go
func osinit() {
	ncpu = getproccount() // 获取cpu的数量
	physHugePageSize = getHugePageSize() // 获取内存页大小
	if iscgo {
		// #42494 glibc and musl reserve some signals for
		// internal use and require they not be blocked by
		// the rest of a normal C runtime. When the go runtime
		// blocks...unblocks signals, temporarily, the blocked
		// interval of time is generally very short. As such,
		// these expectations of *libc code are mostly met by
		// the combined go+cgo system of threads. However,
		// when go causes a thread to exit, via a return from
		// mstart(), the combined runtime can deadlock if
		// these signals are blocked. Thus, don't block these
		// signals when exiting threads.
		// - glibc: SIGCANCEL (32), SIGSETXID (33)
		// - musl: SIGTIMER (32), SIGCANCEL (33), SIGSYNCCALL (34)
		sigdelset(&sigsetAllExiting, 32)
		sigdelset(&sigsetAllExiting, 33)
		sigdelset(&sigsetAllExiting, 34)
	}
	osArchInit()
}
```

```go
// src/runtime/proc.go
// The bootstrap sequence is:
//
//	call osinit
//	call schedinit
//	make & queue new G
//	call runtime·mstart
//
// The new G calls runtime·main.
func schedinit() {
	...

	sched.maxmcount = 10000 // 设置m的最大个数

	// The world starts stopped.
	worldStopped()

	moduledataverify() // 校验各模块中函数符号表，ABI等
	stackinit() // 初始化stackpool
	mallocinit() // 堆内存管理相关初始化
	cpuinit()      // cpu指令集检查
	alginit()      // 加密算法初始化
	fastrandinit() // must run before mcommoninit
	mcommoninit(_g_.m, -1)// 初始化当前m,给他一个唯一id,并添加到allm列表中
	modulesinit()   // provides activeModules
    typelinksinit() // 扫描模块中的类型元数据,为每个模块构造typemap,用于模块间类型指针去重(type pointer de-duplicate)
	itabsinit()     // 把各个模块编译期间生成的itab,添加到全局itabtable 类型断言是使用
	stkobjinit()    // must run before GC starts

	sigsave(&_g_.m.sigmask) // 保存当前线程的信号屏蔽字，用来在非go线程调用go函数前保存其原始信号屏蔽字
	initSigmask = _g_.m.sigmask 

	if offset := unsafe.Offsetof(sched.timeToRun); offset%8 != 0 {
		println(offset)
		throw("sched.timeToRun not aligned to 8 bytes")
	}

	goargs() // 准备命令行参数
	goenvs() // 解析环境变量
	parsedebugvars() //解析运行时调试相关的环境变量godebug,gotraceback...
	gcinit() // 初始化gc,根据环境变量设置gc触发条件

	lock(&sched.lock)
	sched.lastpoll = uint64(nanotime()) // 在调度器中记录上次轮询网络io的时间
    
    // 确认P的个数
	// 默认等于cpu个数，可以通过GOMAXPROCS环境变量更改
	procs := ncpu
	if n, ok := atoi32(gogetenv("GOMAXPROCS")); ok && n > 0 {
		procs = n
	}
    // 根据procs分配p
	if procresize(procs) != nil {
		throw("unknown runnable goroutine during bootstrap")
	}
    
	unlock(&sched.lock)

	// World is effectively started now, as P's can run.
	worldStarted()

	...
}
```

在schedinit中需要注意stackinit函数

```go
// src/runtime/proc.go
func stackinit() {
	if _StackCacheSize&_PageMask != 0 {
		throw("cache size must be a multiple of page size")
	}
	for i := range stackpool {
		stackpool[i].item.span.init()
		lockInit(&stackpool[i].item.mu, lockRankStackpool)
	}
	for i := range stackLarge.free {
		stackLarge.free[i].init()
		lockInit(&stackLarge.lock, lockRankStackLarge)
	}
}
```

stack_pool: 一个数组，每个数组保存的是包含相同大小栈的链表

free: 存储了一个栈的链表，但是这些栈都是在GC时被加入的，并且在回收的时候被清空。并且只有2KB, 4KB, 8KB以及16KB的栈才会被缓存，更大的栈会被直接分配

```go
// src/runtime/proc.go
// Create a new g running fn.
// Put it on the queue of g's waiting to run.
// The compiler turns a go statement into a call to this.
// 以runtime.main为执行入口创建一个goroutinue,并把它添加到当前p的runqueue里
func newproc(fn *funcval) {
	gp := getg() // 获取当前g
	pc := getcallerpc() // 获得调用者下一条需要执行的指令地址
    // 系统调用 切换到g0栈 因为g0栈空间够大
	systemstack(func() {
		newg := newproc1(fn, gp, pc) // 创建一个g

		_p_ := getg().m.p.ptr() // 拿到当前p
        
		runqput(_p_, newg, true) // 将g添加到p的runqueue中

		if mainStarted { // m0是否启动
            
			wakep() // 唤醒p
		}
	})
}

// Create a new g in state _Grunnable, starting at fn. callerpc is the
// address of the go statement that created this. The caller is responsible
// for adding the new g to the scheduler.
func newproc1(fn *funcval, callergp *g, callerpc uintptr) *g {
	_g_ := getg() // g0

	if fn == nil {
		_g_.m.throwing = -1 // do not dump full stacks
		throw("go of nil func value")
	}
    
    // 禁止m抢占,防止并发修改m数据
	acquirem() // disable preemption because it can be holding p in a local var

	_p_ := _g_.m.p.ptr()
	newg := gfget(_p_)// 从p的空闲g队列获取g，一个g执行完后会被回收至p的gFree链表中，这样就可以实现g的重复利用
	if newg == nil {// gFree为空才会真正取创建goroutine
        newg = malg(_StackMin)// 为g分配_StackMin字节的栈空间(2048b)
		casgstatus(newg, _Gidle, _Gdead) // // 将创建的g的状态从_Gidle设置为_Gdead, 如果当前g的原子状态处于Gscan，那么该方法会循环直到Gscan结束
        
        // 将g添加到allgs中,防止gc清除
		allgadd(newg) // publishes with a g->status of Gdead so GC scanner doesn't look at uninitialized stack.
	}
	if newg.stack.hi == 0 {
		throw("newproc1: newg missing stack")
	}

	if readgstatus(newg) != _Gdead {
		throw("newproc1: new g is not Gdead")
	}

    //调整栈顶地址
	totalSize := uintptr(4*goarch.PtrSize + sys.MinFrameSize) // extra space in case of reads slightly beyond frame
	totalSize = alignUp(totalSize, sys.StackAlign)
	sp := newg.stack.hi - totalSize
	spArg := sp
	if usesLR {
		// caller's LR
		*(*uintptr)(unsafe.Pointer(sp)) = 0
		prepGoExitFrame(sp)
		spArg += sys.MinFrameSize
	}

	memclrNoHeapPointers(unsafe.Pointer(&newg.sched), unsafe.Sizeof(newg.sched))//清空goroutine的执行现场，因为G可能从p中取的，需要清除原有数据
	newg.sched.sp = sp // 保存栈顶
	newg.stktopsp = sp // 
    // pc为入口指令 这里pc=goexit+1 这样在执行完该goroutine后会调用goexit回收
    // 也就是把goexit 指令压入协程栈
    /*
	goexit指令如下
	TEXT runtime·goexit(SB),NOSPLIT,$0-0
	BYTE	$0x90	// NOP
	CALL	runtime·goexit1(SB)	// does not return 第二条指令
	// traceback from goexit1 must hit code range of goexit
	BYTE	$0x90	// NOP
	*/
    // newg.sched.pc 表示当 newg 被调度起来运行时从这个地址开始执行指令
	newg.sched.pc = abi.FuncPCABI0(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function
	newg.sched.g = guintptr(unsafe.Pointer(newg))
	gostartcallfn(&newg.sched, fn)// pc被用于sp，当RET的时候pop出goexit，模拟goexit调用fn
	newg.gopc = callerpc// 调用方pc
	newg.ancestors = saveAncestors(callergp)// 记录goroutine调用链
    // 设置 newg 的 startpc 为 fn.fn，该成员主要用于函数调用栈的 traceback 和栈收缩
    // newg 真正从哪里开始执行并不依赖于这个成员，而是 sched.pc
	newg.startpc = fn.fn
	if isSystemGoroutine(newg, false) {
		atomic.Xadd(&sched.ngsys, +1)
	} else {
		// Only user goroutines inherit pprof labels.
		if _g_.m.curg != nil {
			newg.labels = _g_.m.curg.labels
		}
	}
	// Track initial transition?
	newg.trackingSeq = uint8(fastrand())
	if newg.trackingSeq%gTrackingPeriod == 0 {
		newg.tracking = true
	}
	casgstatus(newg, _Gdead, _Grunnable)// 状态置为_Grunnable
	gcController.addScannableStack(_p_, int64(newg.stack.hi-newg.stack.lo)) // gc调度器,栈扫描添加

	if _p_.goidcache == _p_.goidcacheend {
		// Sched.goidgen is the last allocated id,
		// this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch].
		// At startup sched.goidgen=0, so main goroutine receives goid=1.
		_p_.goidcache = atomic.Xadd64(&sched.goidgen, _GoidCacheBatch)
		_p_.goidcache -= _GoidCacheBatch - 1
		_p_.goidcacheend = _p_.goidcache + _GoidCacheBatch
	}
	newg.goid = int64(_p_.goidcache) // 赋予g gid
	_p_.goidcache++ // 
	if raceenabled {
		newg.racectx = racegostart(callerpc)
	}
	if trace.enabled {
		traceGoCreate(newg, newg.startpc)
	}
    releasem(_g_.m)// 释放m,对应acquirem()

	return newg
}
```

经过上面步骤g已经加入本地队列中了,接下来就是进行调度

```go
// src/runtime/proc.go
//go:nosplit
//go:nowritebarrierrec
func mstart0() {
    // 获取g0
	_g_ := getg()

    // 初始化一大堆栈参数
	osStack := _g_.stack.lo == 0
	if osStack {
		// Initialize stack bounds from system stack.
		// Cgo may have left stack size in stack.hi.
		// minit may update the stack bounds.
		//
		// Note: these bounds may not be very accurate.
		// We set hi to &size, but there are things above
		// it. The 1024 is supposed to compensate this,
		// but is somewhat arbitrary.
		size := _g_.stack.hi
		if size == 0 {
			size = 8192 * sys.StackGuardMultiplier
		}
		_g_.stack.hi = uintptr(noescape(unsafe.Pointer(&size)))
		_g_.stack.lo = _g_.stack.hi - size + 1024
	}
	// Initialize stack guard so that we can start calling regular
	// Go code.
	_g_.stackguard0 = _g_.stack.lo + _StackGuard
	// This is the g0, so we can also call go:systemstack
	// functions, which check stackguard1.
	_g_.stackguard1 = _g_.stackguard0
	mstart1()

	// Exit this thread.
	if mStackIsSystemAllocated() {
		// Windows, Solaris, illumos, Darwin, AIX and Plan 9 always system-allocate
		// the stack, but put it in _g_.stack before mstart,
		// so the logic above hasn't set osStack yet.
		osStack = true
	}
	mexit(osStack)
}

// The go:noinline is to guarantee the getcallerpc/getcallersp below are safe,
// so that we can set up g0.sched to return to the call of mstart1 above.
//go:noinline
func mstart1() {
    // 确保g是系统栈上的g0
	// 调度器只在g0上执行
	_g_ := getg()

	if _g_ != _g_.m.g0 {
		throw("bad runtime·mstart")
	}

	// Set up m.g0.sched as a label returning to just
	// after the mstart1 call in mstart0 above, for use by goexit0 and mcall.
	// We're never coming back to mstart1 after we call schedule,
	// so other calls can reuse the current frame.
	// And goexit0 does a gogo that needs to return from mstart1
	// and let mstart0 exit the thread.
    // 保存当前g(因为是新创建的m，所以只能是g0)的sched状态
	_g_.sched.g = guintptr(unsafe.Pointer(_g_))
	_g_.sched.pc = getcallerpc()
	_g_.sched.sp = getcallersp()

	asminit()
    // 初始化m，主要是设置线程的备用信号堆栈和信号掩码
	minit()

	// Install signal handlers; after minit so that minit can
	// prepare the thread to be able to handle the signals.
    // 如果当前g的m是初始m0，执行mstartm0()
	if _g_.m == &m0 {
        // 对于初始m，需要一些特殊处理，主要是设置系统信号量的处理函数
		mstartm0()
	}

    // 如果有m的起始任务函数，则执行，比如 sysmon 函数
	// 对于m0来说，是没有 mstartfn 的
	if fn := _g_.m.mstartfn; fn != nil {
		fn()
	}

	if _g_.m != &m0 {
        // 绑定p
		acquirep(_g_.m.nextp.ptr()) 
		_g_.m.nextp = 0
	}
    // 进入调度循环，永不返回
	schedule() // 开启调度
}
```

